---
title: "<따라 하며 배우는 데이터 과학> 8-9장 연습문제 해답"
author: "권재명"
date: "9/27/2017"
output:
  html_document:
    toc: true
    toc_depth: 3
---

저자 책 웹페이지: <https://dataninja.me/ipds-kr/>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
```

# 원 문제:

- Ch 8 빅데이터 분류분석 I: 기본 개념과 로지스틱 모형
- Ch 9 빅데이터 분류분석 II: 라쏘와 랜덤 포레스트

<https://goo.gl/hmyTre> 혹은 
<https://archive.ics.uci.edu/ml/datasets.html> 
에서 고차원 분류분석 데이터를 찾아서 
로지스틱 분류분석을 실행하고, 
결과를 슬라이드 10여 장 내외로 요약하라.

UCI 보다는 캐글에 있는 다음 자료를 분석해 보자.
<https://www.kaggle.com/ludobenistant/hr-analytics>


# R 환경 준비
일단은 필수패키지인 `tidyverse`, 그리고 
머신러닝을 위한 몇가지 패키지를 로드하자.
(로딩 메시지를 감추기 위해 `suppressMessages()` 명령을 사용.)
```{r}
# install.packages("tidyverse")
suppressMessages(library(tidyverse))

# install.packages(c("ROCR", "MASS", "glmnet", "randomForest", "gbm", "rpart", "boot"))
suppressMessages(library(gridExtra))
suppressMessages(library(ROCR))
suppressMessages(library(MASS))
suppressMessages(library(glmnet))
suppressMessages(library(randomForest))
suppressMessages(library(gbm))
suppressMessages(library(rpart))
suppressMessages(library(boot))
```


책에서 기술한대로 이항 오차 함수, 그리고 `panel.cor` 함수를 정의하자:
```{r}
binomial_deviance <- function(y_obs, yhat){
  epsilon = 0.0001
  yhat = ifelse(yhat < epsilon, epsilon, yhat)
  yhat = ifelse(yhat > 1-epsilon, 1-epsilon, yhat)
  a = ifelse(y_obs==0, 0, y_obs * log(y_obs/yhat))
  b = ifelse(y_obs==1, 0, (1-y_obs) * log((1-y_obs)/(1-yhat)))
  return(2*sum(a + b))
}

# exmaple(pairs) 에서 따옴
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...){
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y))
  txt <- format(c(r, 0.123456789), digits = digits)[1]
  txt <- paste0(prefix, txt)
  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
  text(0.5, 0.5, txt, cex = cex.cor * r)
}

```

자료를 `human-resources-analytics.zip` 파일로 다운받은 후 다음처럼 R에 읽어들인다:

```{r}
df <- read_csv("human-resources-analytics.zip")
glimpse(df)
```

분석의 목적은 다른 변수를 이용하여 `left` 여부를 예측하는 것이다.

각 변수들의 요약통계량을 살펴보자:
```{r}
summary(df)
```

범주형 변수들의 도수분포는 다음과 같다:
```{r}
table(df$left)
table(df$sales)
table(df$salary)
```

수량형 변수들간의 관계는 산점도 행렬로 살펴볼 수 있다:
```{r}
set.seed(2017)
df %>% 
  dplyr::select(-sales, -salary) %>% 
  sample_n(500) %>% 
  pairs(lower.panel=function(x,y){ points(x,y); abline(0, 1, col='red')},
    upper.panel = panel.cor)
```
(`select` 함수가 `MASS` 라이브러리에 재정의 된 관계로 `dplyr::select()`로 표기했다. )
반응변수와 큰 상관관계가 있는 변수는 satisfaction_level 임을 알 수 있고,
설명변수중 past_evaluation, number_projects, average_monthly_hours 간에
비교적 높은 상관관계가 있음을 알 수 있다.

(혹시 시간이 걸리더라도 좀 더 고급진 산점도행렬을 얻고자 한다면 다음처럼
`GGally::ggparis()` 함수를 사용하자)
```{r}
# install.packages("GGally")
# suppressMessages(library(GGally))
# set.seed(2017); df %>% sample_n(1000)  %>% GGally::ggpairs()
```

모형행렬은 반응변수 `left` 를 제외한 모든 변수들을
`model.matrix()` 에 입력해주면 얻을 수 있다:
```{r}
x <- model.matrix( ~ . - left, data=df)
glimpse(x)
colnames(x)
```

모형의 차원은 $p=19$ 임을 알 수 있다.


## 훈련, 검증, 테스트셋의 구분
원 데이터를 6:4:4 비율로 훈련, 검증, 테스트셋으로 나누도록 하자.
```{r}
set.seed(2017)
n <- nrow(df)
idx <- 1:n
training_idx <- sample(idx, n * .60)
idx <- setdiff(idx, training_idx)
validate_idx = sample(idx, n * .20)
test_idx <- setdiff(idx, validate_idx)
length(training_idx)
length(validate_idx)
length(test_idx)
training <- df[training_idx,]
validation <- df[validate_idx,]
test <- df[test_idx,]
```



## A. 로지스틱 회귀분석

```{r}
ad_glm_full <- glm(left ~ ., data=training, family=binomial)
summary(ad_glm_full)
```


로지스틱 모형의 예측 정확도 지표는 다음처럼 계산하고 시각화할 수 있다:
```{r}
y_obs <- validation$left
yhat_lm <- predict(ad_glm_full, newdata=validation, type='response')
ggplot(data.frame(y_obs, yhat_lm),
             aes(yhat_lm, fill=factor(y_obs))) +
  geom_density(alpha=.5)
binomial_deviance(y_obs, yhat_lm)
pred_lm <- prediction(yhat_lm, y_obs)
perf_lm <- performance(pred_lm, measure = "tpr", x.measure = "fpr")
plot(perf_lm, col='black', main="ROC Curve for GLM")
performance(pred_lm, "auc")@y.values[[1]]
```


## B. glmnet 함수를 통한 라쏘 모형, 능형회귀, 변수선택

```{r}
xx <- model.matrix(left ~ .-1, df)
x <- xx[training_idx, ]
y <- training$left
ad_glmnet_fit <- glmnet(x, y)

```


```{r eval=FALSE}

plot(ad_glmnet_fit)

coef(ad_glmnet_fit, s = c(.1713, .1295))



ad_cvfit <- cv.glmnet(x, y, family = "binomial")

plot(ad_cvfit)

png("../../plots/9-2.png", 5.5, 4, units='in', pointsize=9, res=600)
plot(ad_cvfit)
dev.off()

log(ad_cvfit$lambda.min)
log(ad_cvfit$lambda.1se)

coef(ad_cvfit, s=ad_cvfit$lambda.1se)
coef(ad_cvfit, s="lambda.1se")

length(which(coef(ad_cvfit, s="lambda.min")>0))
length(which(coef(ad_cvfit, s="lambda.1se")>0))

# 9.1.4.  값의 선택

set.seed(1607)
foldid <- sample(1:10, size=length(y), replace=TRUE)
cv1 <- cv.glmnet(x, y, foldid=foldid, alpha=1, family='binomial')
cv.5 <- cv.glmnet(x, y, foldid=foldid, alpha=.5, family='binomial')
cv0 <- cv.glmnet(x, y, foldid=foldid, alpha=0, family='binomial')

png("../../plots/9-3.png", 5.5, 4, units='in', pointsize=7, res=600)
par(mfrow=c(2,2))
plot(cv1, main="Alpha=1.0")
plot(cv.5, main="Alpha=0.5")
plot(cv0, main="Alpha=0.0")
plot(log(cv1$lambda), cv1$cvm, pch=19, col="red",
     xlab="log(Lambda)", ylab=cv1$name, main="alpha=1.0")
points(log(cv.5$lambda), cv.5$cvm, pch=19, col="grey")
points(log(cv0$lambda), cv0$cvm, pch=19, col="blue")
legend("topleft", legend=c("alpha= 1", "alpha= .5", "alpha 0"),
       pch=19, col=c("red","grey","blue"))
dev.off()


predict(ad_cvfit, s="lambda.1se", newx = x[1:5,], type='response')

y_obs <- ifelse(validation$left == ">50K", 1, 0)
yhat_glmnet <- predict(ad_cvfit, s="lambda.1se", newx=xx[validate_idx,], type='response')
yhat_glmnet <- yhat_glmnet[,1] # change to a vectro from [n*1] matrix
binomial_deviance(y_obs, yhat_glmnet)
# [1] 4257.118
pred_glmnet <- prediction(yhat_glmnet, y_obs)
perf_glmnet <- performance(pred_glmnet, measure="tpr", x.measure="fpr")

performance(pred_glmnet, "auc")@y.values[[1]]

png("../../plots/9-4.png", 5.5, 4, units='in', pointsize=9, res=600)
plot(perf_lm, col='black', main="ROC Curve")
plot(perf_glmnet, col='blue', add=TRUE)
abline(0,1, col='gray')
legend('bottomright', inset=.1,
       legend=c("GLM", "glmnet"),
       col=c('black', 'blue'), lty=1, lwd=2)
dev.off()


# 9.2. 나무모형
library(rpart)
cvr_tr <- rpart(left ~ ., data = training)
cvr_tr


printcp(cvr_tr)
summary(cvr_tr)



png("../../plots/9-6.png", 5.5, 4, units='in', pointsize=9, res=600)
opar <- par(mfrow = c(1,1), xpd = NA)
plot(cvr_tr)
text(cvr_tr, use.n = TRUE)
par(opar)
dev.off()


yhat_tr <- predict(cvr_tr, validation)
yhat_tr <- yhat_tr[,">50K"]
binomial_deviance(y_obs, yhat_tr)
pred_tr <- prediction(yhat_tr, y_obs)
perf_tr <- performance(pred_tr, measure = "tpr", x.measure = "fpr")
performance(pred_tr, "auc")@y.values[[1]]

png("../../plots/9-7.png", 5.5, 4, units='in', pointsize=9, res=600)
plot(perf_lm, col='black', main="ROC Curve")
plot(perf_tr, col='blue', add=TRUE)
abline(0,1, col='gray')
legend('bottomright', inset=.1,
    legend = c("GLM", "Tree"),
    col=c('black', 'blue'), lty=1, lwd=2)
dev.off()


# 9.3. 랜덤 포레스트 -----------

set.seed(1607)
ad_rf <- randomForest(left ~ ., training)
ad_rf

png("../../plots/9-8.png", 5.5, 4, units='in', pointsize=9, res=600)
plot(ad_rf)
dev.off()

tmp <- importance(ad_rf)
head(round(tmp[order(-tmp[,1]), 1, drop=FALSE], 2), n=10)

png("../../plots/9-9.png", 5.5, 4, units='in', pointsize=9, res=600)
varImpPlot(ad_rf)
dev.off()

predict(ad_rf, newdata = df[1:5,])

predict(ad_rf, newdata = df[1:5,], type="prob")


yhat_rf <- predict(ad_rf, newdata=validation, type='prob')[,'>50K']
binomial_deviance(y_obs, yhat_rf)
pred_rf <- prediction(yhat_rf, y_obs)
perf_rf <- performance(pred_rf, measure="tpr", x.measure="fpr")
performance(pred_tr, "auc")@y.values[[1]]

png("../../plots/9-10.png", 5.5, 4, units='in', pointsize=9, res=600)
plot(perf_lm, col='black', main="ROC Curve")
plot(perf_glmnet, add=TRUE, col='blue')
plot(perf_rf, add=TRUE, col='red')
abline(0,1, col='gray')
legend('bottomright', inset=.1,
       legend = c("GLM", "glmnet", "RF"),
       col=c('black', 'blue', 'red'), lty=1, lwd=2)
dev.off()


# 9.3.5. 예측확률값 자체의 비교
p1 <- data.frame(yhat_glmnet, yhat_rf) %>%
  ggplot(aes(yhat_glmnet, yhat_rf)) +
  geom_point(alpha=.5) +
  geom_abline() +
  geom_smooth()
p2 <- reshape2::melt(data.frame(yhat_glmnet, yhat_rf)) %>%
  ggplot(aes(value, fill=variable)) +
  geom_density(alpha=.5)
grid.arrange(p1, p2, ncol=2)
g <- arrangeGrob(p1, p2, ncol=2)
ggsave("../../plots/9-11.png", g, width=5.5*1.2, height=4*.8, units='in', dpi=600)


# 9.4. 부스팅 ----------

set.seed(1607)
df_gbm <- training %>% mutate(left=ifelse(left == ">50K", 1, 0))
ad_gbm <- gbm(left ~ ., data=df_gbm,
             distribution="bernoulli",
             n.trees=50000, cv.folds=3, verbose=TRUE)
(best_iter <- gbm.perf(ad_gbm, method="cv"))

ad_gbm2 <- gbm.more(ad_gbm, n.new.trees=10000)
(best_iter <- gbm.perf(ad_gbm2, method="cv"))


png("../../plots/9-12.png", 5.5, 4, units='in', pointsize=9, res=600)
(best_iter <- gbm.perf(ad_gbm2, method="cv"))
dev.off()


predict(ad_gbm, n.trees=best_iter, newdata=df_gbm[1:5,], type='response')

yhat_gbm <- predict(ad_gbm, n.trees=best_iter, newdata=validation, type='response')
binomial_deviance(y_obs, yhat_gbm)
pred_gbm <- prediction(yhat_gbm, y_obs)
perf_gbm <- performance(pred_gbm, measure="tpr", x.measure="fpr")
performance(pred_gbm, "auc")@y.values[[1]]


png("../../plots/9-13.png", 5.5, 4, units='in', pointsize=9, res=600)
plot(perf_lm, col='black', main="ROC Curve")
plot(perf_glmnet, add=TRUE, col='blue')
plot(perf_rf, add=TRUE, col='red')
plot(perf_gbm, add=TRUE, col='cyan')
abline(0,1, col='gray')
legend('bottomright', inset=.1,
    legend=c("GLM", "glmnet", "RF", "GBM"),
    col=c('black', 'blue', 'red', 'cyan'), lty=1, lwd=2)
dev.off()



# 9.5. 모형 비교, 최종 모형 선택, 일반화 성능 평가 ----


png("../../plots/9-14.png", 5.5, 4, units='in', pointsize=9, res=600)
pairs(data.frame(y_obs=y_obs,
                yhat_lm=yhat_lm,
                yhat_glmnet=c(yhat_glmnet),
              yhat_rf=yhat_rf,
                yhat_gbm=yhat_gbm),
    lower.panel=function(x,y){ points(x,y); abline(0, 1, col='red')},
    upper.panel = panel.cor)
dev.off()


# 9.5.3. 테스트셋을 이용한 일반화능력 계산
y_obs_test <- ifelse(test$left == ">50K", 1, 0)
yhat_gbm_test <- predict(ad_gbm, n.trees=best_iter, newdata=test, type='response')
binomial_deviance(y_obs_test, yhat_gbm_test)
pred_gbm_test <- prediction(yhat_gbm_test, y_obs_test)
performance(pred_gbm_test, "auc")@y.values[[1]]

# 9.6.5. 캐럿 (caret) 패키지
install.packages("caret", dependencies = c("Depends", "Suggests"))



# This is for the earlier ROC curve example. ---
{
  png("../../plots/8-1.png", 5.5*1.2, 4*.8, units='in', pointsize=9, res=600)
  opar <- par(mfrow=c(1,2))
  plot(perf_lm, col='black', main="ROC Curve")
  plot(perf_tr, col='blue', add=TRUE)
  abline(0,1, col='gray')
  legend('bottomright', inset=.1,
      legend = c("GLM", "Tree"),
      col=c('black', 'blue'), lty=1, lwd=2)
  plot(perf_lm, col='black', main="ROC Curve")
  plot(perf_glmnet, add=TRUE, col='blue')
  plot(perf_rf, add=TRUE, col='red')
  plot(perf_gbm, add=TRUE, col='cyan')
  abline(0,1, col='gray')
  legend('bottomright', inset=.1,
      legend=c("GLM", "glmnet", "RF", "GBM"),
      col=c('black', 'blue', 'red', 'cyan'), lty=1, lwd=2)
  par(opar)
  dev.off()
}

```


